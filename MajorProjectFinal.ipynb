{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "XmlI0mPbwcKf"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit google-generativeai pyngrok --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD8CpgGFraY-pZFKNN4CLjjGkHqHOhIX-c\"  # Replace with your Gemini API key\n"
      ],
      "metadata": {
        "id": "dA61eL2PwoxP"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile emotion_detector.py\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n",
        "\n",
        "def detect_emotion(text):\n",
        "    prompt = f\"Detect the dominant emotion from this text: '{text}'. Respond with one word like 'fear', 'joy', 'sadness', 'anger', or 'surprise'.\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip().lower()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKP6xpmjwrJG",
        "outputId": "f635bb4a-9144-4eb1-fbfa-bb6f51736ff2"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting emotion_detector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile story_generator.py\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n",
        "\n",
        "def continue_story(scene, emotion):\n",
        "    prompt = (\n",
        "        f\"Continue this story in the tone of {emotion}. Make it emotionally rich and realistic.\\n\\n\"\n",
        "        f\"Scene: {scene}\\n\\n\"\n",
        "        f\"Continuation:\"\n",
        "    )\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20oXxx4kwuKG",
        "outputId": "6548065f-dcef-463e-dd58-c68a540e4d92"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting story_generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile image_generator.py\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "import torch\n",
        "\n",
        "# Load the model\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/sdxl-turbo\",\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    variant=\"fp16\" if torch.cuda.is_available() else None,\n",
        "    use_safetensors=True\n",
        ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def generate_emotion_image(prompt, emotion):\n",
        "    styled_prompt = (\n",
        "        f\"Highly detailed, cinematic, ultra-realistic portrait of a real human showing strong {emotion.lower()} emotion. \"\n",
        "        f\"{prompt}, expressive facial features matching the emotion, dramatic but natural lighting, realistic background, \"\n",
        "        f\"35mm photography, shallow depth of field, photorealism, 8k resolution\"\n",
        "    )\n",
        "    result = pipe(prompt=styled_prompt, guidance_scale=1.5, num_inference_steps=4)\n",
        "    image = result.images[0]\n",
        "    filename = f\"{emotion.lower()}_image.png\"\n",
        "    image.save(filename)\n",
        "    return filename\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0z1IsNGwxLY",
        "outputId": "86240594-19cb-4dc0-c956-f83ffe463e20"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting image_generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile image_prompt_generator.py\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n",
        "\n",
        "def generate_image_prompt(scene, emotion):\n",
        "    prompt = (\n",
        "        f\"Generate a detailed visual prompt for an image showing the emotion '{emotion}' in the following scene:\\n\\n\"\n",
        "        f\"{scene}\\n\\n\"\n",
        "        f\"Make sure the facial expressions and environment reflect the emotion clearly.\"\n",
        "    )\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNCmb9DE_RKo",
        "outputId": "a4aca7ef-a8a0-413a-dd09-1a8395e4d9bc"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting image_prompt_generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from emotion_detector import detect_emotion\n",
        "from story_generator import continue_story\n",
        "from image_prompt_generator import generate_image_prompt\n",
        "from image_generator import generate_emotion_image  # Make sure this file exists\n",
        "\n",
        "st.set_page_config(page_title=\"Emotion-Aware Story Generator\", layout=\"centered\")\n",
        "st.title(\"ðŸŽ­ Emotion-Aware AI Story Assistant\")\n",
        "\n",
        "scene_input = st.text_area(\"Enter the opening scene:\", height=150)\n",
        "\n",
        "if st.button(\"Generate\"):\n",
        "    if not scene_input.strip():\n",
        "        st.error(\"Please enter some text to analyze.\")\n",
        "    else:\n",
        "        with st.spinner(\"Detecting emotion...\"):\n",
        "            emotion = detect_emotion(scene_input)\n",
        "            st.success(f\"Detected Emotion: **{emotion.capitalize()}**\")\n",
        "\n",
        "        with st.spinner(\"Generating continuation...\"):\n",
        "            continuation = continue_story(scene_input, emotion)\n",
        "            st.subheader(\"ðŸ“˜ Continued Story\")\n",
        "            st.write(continuation)\n",
        "\n",
        "        with st.spinner(\"Generating visual prompt...\"):\n",
        "            img_prompt = generate_image_prompt(scene_input, emotion)\n",
        "            st.text(\"Prompt used for image generation:\")\n",
        "            st.write(img_prompt)\n",
        "\n",
        "        with st.spinner(\"Generating image...\"):\n",
        "            image_path = generate_emotion_image(scene_input,emotion)\n",
        "            st.image(image_path, caption=f\"Generated image for '{emotion}'\", use_container_width=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWWscqHLzTA8",
        "outputId": "3bd684c7-45c8-41e8-ccff-e394b33105f1"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken $30ttouU1Ge5YlOa3heZ8CMvshl4_2guUo9MUPdEwCK5Su9n6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b8i7qa_6Ukj",
        "outputId": "e18d6bec-5bc8-4f68-bf5e-cc32bb3b37bb"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Set your Ngrok authtoken\n",
        "ngrok.set_auth_token(\"30ttouU1Ge5YlOa3heZ8CMvshl4_2guUo9MUPdEwCK5Su9n6\")\n",
        "\n",
        "# Kill any existing tunnels (just in case)\n",
        "ngrok.kill()\n",
        "\n",
        "# Expose the Streamlit port (7860)\n",
        "public_url = ngrok.connect(7860) # Pass the port directly\n",
        "print(f\"ðŸš€ Public link: {public_url}\")\n",
        "\n",
        "# Run the Streamlit app\n",
        "!streamlit run app.py --server.port 7860 --server.enableCORS false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XTIU6cFzNmB",
        "outputId": "6492903a-fd24-4c4b-dbf1-ab87dc83af9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Public link: NgrokTunnel: \"https://49f70232e99c.ngrok-free.app\" -> \"http://localhost:7860\"\n",
            "2025-08-06 06:46:47.475 \n",
            "Warning: the config option 'server.enableCORS=false' is not compatible with\n",
            "'server.enableXsrfProtection=true'.\n",
            "As a result, 'server.enableCORS' is being overridden to 'true'.\n",
            "\n",
            "More information:\n",
            "In order to protect against CSRF attacks, we send a cookie with each request.\n",
            "To do so, we must specify allowable origins, which places a restriction on\n",
            "cross-origin resource sharing.\n",
            "\n",
            "If cross origin resource sharing is required, please disable server.enableXsrfProtection.\n",
            "            \n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:7860\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:7860\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.204.243.208:7860\u001b[0m\n",
            "\u001b[0m\n",
            "2025-08-06 06:47:30.807735: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754462851.176313   27358 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754462851.280422   27358 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Loading pipeline components...: 100% 7/7 [00:06<00:00,  1.09it/s]\n",
            "100% 4/4 [08:31<00:00, 127.78s/it]\n",
            " 25% 1/4 [02:08<06:25, 128.36s/it]"
          ]
        }
      ]
    }
  ]
}